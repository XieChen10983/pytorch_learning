1. 总过程：
    （1）定义自己的网络
    （2）定义自己的数据集
    （3）实例化自己的网络，数据集（以data_loader的形式），优化器，损失函数
    （4）在每个epoch中，在每个batch中循环：
        （a）将数据集代入自己的实例化网络中，计算出预测值。
        （b）根据损失函数计算损失
        （c）优化器参数清零、损失反向传播、优化器参数更新

2. 定义自己的网络（需要继承torch.nn.Module模块）
    class Net(nn.Module):
        def __init__(self):
            super().__init__()                                                  # 以上三层是固定模式，继承了nn.Module的参数
            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)                        # 定义模型的每一层
            ...                                                                 # 继续定义模型所要用的每一层

        def forward(self, x):                                                   # 构建模型的结构，并且根据结构和输入得出
            x = torch.relu(torch.max_pool2d(self.conv1(x), 2))                  # 每一层的输出
            x = torch.relu(torch.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
            x = x.view(-1, 320)
            x = torch.relu(self.fc1(x))
            x = torch.dropout(x, train=True, p=0.1)
            x = self.fc2(x)
            return torch.log_softmax(x, dim=0)                                  # 返回最后的输出


3. 定义自己的数据集（需要继承torch.utils.data.Dataset模块），之后可以用于dataloader
    class MNIST_DataSet(Dataset):                                               # 此仅对ndarray图像数据而言，对于其它类型的
        def __init__(self, data_ndarray, label_ndarray, size=(224, 224)):       # 数据如PIL.Image类型，在__getitem__函数中
            self.files = data_ndarray                                           # 做相应的改动即可
            self.labels = label_ndarray
            self.size = size

        def __len__(self):
            return len(self.files)

        def __getitem__(self, item):
            img = np.array(Image.fromarray(self.files[item]).resize(self.size))
            label = self.labels[item]
            return img, label

4. 实例化
    net = Net()                                                                 # 实例化自己的网络
    training_dset = MNIST_DataSet(training_data, training_label, size=(28, 28)) # 将数据变为dataset类型
    train_loader = DataLoader(training_dset, batch_size=32, shuffle=True, num_workers=0)  # 将dataset数据封装为dataloader
    optimizer = optim.Adam(params=net.parameters(), lr=0.01, weight_decay=0.01) # 实例化优化器
    Loss_function = torch.nn.CrossEntropyLoss()                                 # 实例化损失函数

5. 循环更新参数
    for EPO in range(1, EPOCH + 1):
        for Batch_index, (Data, Target) in enumerate(DATA_LOADER):
            Data = Data.view(-1, 1, 28, 28)
            Target = Target.long()                                              # 使用某些损失函数时，数据类型不能为int
            Output = MODEL(Data)
            Output_numpy = Output.detach().numpy()
            predict_target = torch.from_numpy(np.argmax(Output_numpy, axis=1))
            Loss = Loss_function(Output, Target)                                # 根据损失函数计算损失
            OPTIMIZER.zero_grad()                                               # 优化器参数清零
            Loss.backward()                                                     # 损失反向传播
            OPTIMIZER.step()                                                    # 优化器参数更新
